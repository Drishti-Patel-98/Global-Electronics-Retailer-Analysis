{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a994ae6-5de0-4e5c-907a-85bd75eeee40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values found in Customers data.\n",
      "No missing values found in Products data.\n",
      "Warning: The following columns in Stores have missing values:\n",
      "Square Meters    1\n",
      "dtype: int64\n",
      "Warning: The following columns in Sales have missing values:\n",
      "Delivery Date    49719\n",
      "dtype: int64\n",
      "No missing values found in Exchange_Rates data.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "%matplotlib inline\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def Load_Data():\n",
    "    Customers = pd.read_csv('Data/Customers.csv',encoding= 'unicode_escape')\n",
    "    Products = pd.read_csv('Data/Products.csv',encoding= 'unicode_escape')\n",
    "    Stores = pd.read_csv('Data/Stores.csv',encoding= 'unicode_escape')\n",
    "    Sales = pd.read_csv('Data/Sales.csv',encoding= 'unicode_escape')\n",
    "    Exchange_Rates = pd.read_csv('Data/Exchange_Rates.csv',encoding= 'unicode_escape')\n",
    "    \n",
    "    return Customers, Products, Stores, Sales, Exchange_Rates\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------- \n",
    "def Clean_Customer_Data(Customers):\n",
    "    #Drop duplicates keeping only the first occurrence\n",
    "    Customers = Customers.drop_duplicates()\n",
    "\n",
    "    #Rename columns\n",
    "    Customers = Customers.rename(columns={'Name': 'Customer Name', \n",
    "                                          'City': 'Customer City',\n",
    "                                          'State Code':'Customer State Code',\n",
    "                                          'State':'Customer State',\n",
    "                                          'Zip Code':'Customer Zip Code',\n",
    "                                          'Country':'Customer Country',\n",
    "                                          'Continent':'Customer Continent'\n",
    "                                         }\n",
    "                                )\n",
    "    #Convert datatype of 'Birthday' from string to Date\n",
    "    Customers['Birthday'] = pd.to_datetime(Customers['Birthday'],format='%m/%d/%Y', errors='coerce')\n",
    "    \n",
    "    #Replace null with NA(Napoli)\n",
    "    Customers.loc[Customers['Customer State'] == 'Napoli', 'Customer State Code'] = 'NA'\n",
    "    \n",
    "    # Check for nulls and show warning\n",
    "    null_customer_summary = Customers.isnull().sum()\n",
    "    null_customer_columns = null_customer_summary[null_customer_summary > 0]\n",
    "    \n",
    "    if not null_customer_columns.empty:\n",
    "        print(\"Warning: The following columns have missing values:\")\n",
    "        print(null_customer_columns)\n",
    "    else:\n",
    "        print(\"No missing values found in Customers data.\")\n",
    "    \n",
    "    return Customers\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def Clean_Product_Data(Products):\n",
    "    #Drop duplicates keeping only the first occurrence\n",
    "    Products = Products.drop_duplicates()\n",
    "    \n",
    "    #Convert datatype of 'Unit Cost USD' from string to float\n",
    "    Products['Unit Cost USD'] = (Products['Unit Cost USD']\n",
    "                                 .astype(str)                              # Convert everything to string\n",
    "                                 .str.replace('[$,]', '', regex=True)      # Remove $ and commas\n",
    "                                 .replace({'nan': None, '': None})         # Optional: Handle empty strings\n",
    "                                 .astype(float)                            # Convert to float\n",
    "                                 .fillna(0)                                # fill missing cost with 0\n",
    "                                )\n",
    "    \n",
    "    #Convert datatype of 'Unit Price USD' from string to float\n",
    "    Products['Unit Price USD'] = (Products['Unit Price USD']\n",
    "                                  .astype(str)                              # Convert everything to string\n",
    "                                  .str.replace('[$,]', '', regex=True)      # Remove $ and commas\n",
    "                                  .replace({'nan': None, '': None})         # Optional: Handle empty strings\n",
    "                                  .astype(float)                            # Convert to float\n",
    "                                  .fillna(0)                                # fill missing price with 0\n",
    "                                 )\n",
    "    \n",
    "    # Check for nulls and show warning\n",
    "    null_product_summary = Products.isnull().sum()\n",
    "    null_product_columns = null_product_summary[null_product_summary > 0]\n",
    "    \n",
    "    if not null_product_columns.empty:\n",
    "        print(\"Warning: The following columns in Products have missing values:\")\n",
    "        print(null_product_columns)\n",
    "    else:\n",
    "        print(\"No missing values found in Products data.\")\n",
    "    return Products\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def Clean_Store_Data(Stores):\n",
    "    #Drop duplicates keeping only the first occurrence\n",
    "    Stores = Stores.drop_duplicates()\n",
    "    \n",
    "    #Convert datatype of 'Open Date' from string to Date\n",
    "    Stores['Open Date'] = pd.to_datetime(Stores['Open Date'],format='%m/%d/%Y', errors='coerce')\n",
    "    \n",
    "    #Rename columns\n",
    "    Stores = Stores.rename(columns={'Country': 'Store Country', \n",
    "                                    'State': 'Store State',\n",
    "                                    'Open Date':'Store Open Date'\n",
    "                                   }\n",
    "                          )\n",
    "    \n",
    "    # Check for nulls and show warning\n",
    "    null_store_summary = Stores.isnull().sum()\n",
    "    null_store_columns = null_store_summary[null_store_summary > 0]\n",
    "\n",
    "    if not null_store_columns.empty:\n",
    "        print(\"Warning: The following columns in Stores have missing values:\")\n",
    "        print(null_store_columns)\n",
    "    else:\n",
    "        print(\"No missing values found in Stores data.\")\n",
    "    \n",
    "    return Stores\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def Clean_ExchangeRate_Data(Exchange_Rates):\n",
    "    #Drop duplicates keeping only the first occurrence\n",
    "    Exchange_Rates = Exchange_Rates.drop_duplicates()\n",
    "    \n",
    "    #Convert datatype of 'Date' from string to Date\n",
    "    Exchange_Rates['Date'] = pd.to_datetime(Exchange_Rates['Date'],format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "    # Check for nulls and show warning\n",
    "    null_exchange_rate_summary = Exchange_Rates.isnull().sum()\n",
    "    null_exchange_rate_columns = null_exchange_rate_summary[null_exchange_rate_summary > 0]\n",
    "\n",
    "    if not null_exchange_rate_columns.empty:\n",
    "        print(\"Warning: The following columns in Exchange_Rates have missing values:\")\n",
    "        print(null_exchange_rate_columns)\n",
    "    else:\n",
    "        print(\"No missing values found in Exchange_Rates data.\")\n",
    "    \n",
    "    return Exchange_Rates\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def Clean_Sales_Data(Sales):\n",
    "    #Drop duplicates keeping only the first occurrence\n",
    "    Sales = Sales.drop_duplicates()\n",
    "    \n",
    "    #Convert datatype of 'Order Date' from string to Date\n",
    "    Sales['Order Date'] = pd.to_datetime(Sales['Order Date'],format='%m/%d/%Y', errors='coerce')\n",
    "    \n",
    "    #Convert datatype of 'Delivery Date' from string to Date\n",
    "    Sales['Delivery Date'] = pd.to_datetime(Sales['Delivery Date'],format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "    # Fill missing Quantity with 0 to avoid errors later\n",
    "    Sales['Quantity'] = Sales['Quantity'].fillna(0)\n",
    "\n",
    "    # Check for nulls and show warning\n",
    "    null_sales_summary = Sales.isnull().sum()\n",
    "    null_sales_columns = null_sales_summary[null_sales_summary > 0]\n",
    "    \n",
    "    if not null_sales_columns.empty:\n",
    "        print(\"Warning: The following columns in Sales have missing values:\")\n",
    "        print(null_sales_columns)\n",
    "    else:\n",
    "        print(\"No missing values found in Sales data.\")\n",
    "    \n",
    "    return Sales\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def Combine_Data(Customers, Products, Stores, Sales, Exchange_Rates):\n",
    "    #Merge Sales with Product on ProductKey\n",
    "    Sales_Products = pd.merge(Sales,Products,on='ProductKey',how='inner')\n",
    "    \n",
    "    #Merge Customers on CustomerKey\n",
    "    Sales_Products_Customers = pd.merge(Sales_Products,Customers,on='CustomerKey',how='inner')\n",
    "\n",
    "    #Merge Stores on StoreKey\n",
    "    Full_Data = pd.merge(Sales_Products_Customers,Stores,on='StoreKey',how='inner')\n",
    "\n",
    "    #Calculate Sales Amount, Cost and Profit\n",
    "    Full_Data['Sales Amount USD'] = Full_Data['Quantity'] * Full_Data['Unit Price USD']\n",
    "    Full_Data['Cost'] = Full_Data['Quantity'] * Full_Data['Unit Cost USD']\n",
    "    Full_Data['Profit'] = Full_Data['Sales Amount USD'] - Full_Data['Cost']\n",
    "    \n",
    "    # Calculate Profit Margin safely (avoid division by zero)\n",
    "    Full_Data['Profit_Margin'] = np.where(Full_Data['Sales Amount USD'] != 0,\n",
    "                                          Full_Data['Profit'] / Full_Data['Sales Amount USD'],\n",
    "                                          0\n",
    "                                         )\n",
    "    \n",
    "    return Full_Data\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def Analyze_Sales(Full_Data):\n",
    "    figs = []\n",
    "\n",
    "    formatter = ticker.FuncFormatter(lambda x, pos: f'{x*1e-6:.2f}M')  # define here\n",
    "    \n",
    "    # Monthly Sales vs Profit\n",
    "    monthly_metrics = Full_Data.groupby(Full_Data['Order Date'].dt.to_period('M')).agg({\n",
    "        'Sales Amount USD': 'sum',\n",
    "        'Profit': 'sum'\n",
    "    }).reset_index()\n",
    "    monthly_metrics['Profit_Margin'] = monthly_metrics['Profit'] / monthly_metrics['Sales Amount USD']\n",
    "    monthly_metrics['Order Date'] = monthly_metrics['Order Date'].dt.to_timestamp()\n",
    "    fig3, ax3 = plt.subplots(figsize=(12,8))\n",
    "    ax3.plot(monthly_metrics['Order Date'], monthly_metrics['Sales Amount USD'], label='Revenue', marker='o')\n",
    "    ax3.plot(monthly_metrics['Order Date'], monthly_metrics['Profit'], label='Profit', marker='o')\n",
    "    ax3.yaxis.set_major_formatter(formatter)\n",
    "    ax3.set_title('Monthly Sales vs Profit')\n",
    "    ax3.set_xlabel('Month')\n",
    "    ax3.set_ylabel('Sales Amount (USD)')\n",
    "    ax3.legend()\n",
    "    figs.append(fig3)\n",
    "    plt.close(fig3)\n",
    "\n",
    "    # Sales by Country\n",
    "    Country_Sales = Full_Data.groupby('Store Country')['Sales Amount USD'].sum().reset_index().sort_values(by='Sales Amount USD', ascending=False)\n",
    "    fig4 = px.choropleth(\n",
    "        Country_Sales,\n",
    "        locations='Store Country',\n",
    "        locationmode='country names',\n",
    "        color='Sales Amount USD',\n",
    "        hover_name='Store Country',\n",
    "        title='Sales by Country',\n",
    "        width=1000,\n",
    "        height=600\n",
    "    )\n",
    "    #figs.append(fig4) #Not appending into report as the current PDF function is not supporting plottly. Future work****\n",
    "    #plt.close(fig4)\n",
    "\n",
    "    # Sales by Country and State\n",
    "    Grouped_Country_State = Full_Data.groupby(['Store Country', 'Store State'],observed=False)['Sales Amount USD'].sum().reset_index()\n",
    "    Country_Totals = Grouped_Country_State.groupby('Store Country')['Sales Amount USD'].sum().sort_values()\n",
    "    Grouped_Country_State['Label'] = Grouped_Country_State['Store Country'] + ' - ' + Grouped_Country_State['Store State']\n",
    "    Country_Order = Country_Totals.index.tolist()\n",
    "    Grouped_Country_State['Store Country'] = pd.Categorical(Grouped_Country_State['Store Country'], categories=Country_Order, ordered=True)\n",
    "    Grouped_Country_State = Grouped_Country_State.sort_values(['Store Country', 'Sales Amount USD'], ascending=[True, True])\n",
    "    palette = sns.color_palette(\"Spectral\", n_colors=len(Country_Order))\n",
    "    country_colors = dict(zip(Country_Order, palette))\n",
    "    Grouped_Country_State['Color'] = Grouped_Country_State['Store Country'].astype(str).map(country_colors)\n",
    "\n",
    "    fig5, ax5 = plt.subplots(figsize=(12, 10))\n",
    "    bars = ax5.barh(Grouped_Country_State['Label'], Grouped_Country_State['Sales Amount USD'], color=Grouped_Country_State['Color'])\n",
    "    ax5.set_title('Sales by Country and State')\n",
    "    ax5.set_xlabel('Total Sales (USD)')\n",
    "    ax5.set_ylabel('Country - State')\n",
    "    ax5.xaxis.set_major_formatter(formatter)\n",
    "    ax5.tick_params(axis='y', labelsize=8)\n",
    "    max_sales = Country_Totals.max()\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        label = f\"${width * 1e-6:.2f}M\"\n",
    "        ax5.text(width + max_sales * 0.01, bar.get_y() + bar.get_height() / 2, label, va='center')\n",
    "    plt.tight_layout()\n",
    "    figs.append(fig5)\n",
    "    plt.close(fig5)\n",
    "\n",
    "    return figs\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def Analyze_Stores(Full_Data):\n",
    "    figs = []\n",
    "\n",
    "    formatter = ticker.FuncFormatter(lambda x, pos: f'{x*1e-6:.2f}M')\n",
    "\n",
    "    # 1. Top 10 and Bottom 10 Stores by Revenue\n",
    "    Store_Sales = Full_Data.groupby('StoreKey')['Sales Amount USD'].sum().sort_values(ascending=False).reset_index()\n",
    "    Store_Sales_Top10 = Store_Sales.head(10)\n",
    "    Store_Sales_Bottom10 = Store_Sales.tail(10)\n",
    "\n",
    "    fig1, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "    sns.barplot(data=Store_Sales_Top10 , x='StoreKey', y='Sales Amount USD',\n",
    "                order=Store_Sales_Top10.sort_values('Sales Amount USD', ascending=False).StoreKey, ax=ax1)\n",
    "    ax1.yaxis.set_major_formatter(formatter)\n",
    "    ax1.set_title('Top 10 Stores by Revenue')\n",
    "    ax1.set_xlabel('Store Key')\n",
    "    ax1.set_ylabel('Total Sales (USD)')\n",
    "    for bar in ax1.patches:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, height, f'{height*1e-6:.2f}M', ha='center', va='bottom')\n",
    "\n",
    "    sns.barplot(data=Store_Sales_Bottom10 , x='StoreKey', y='Sales Amount USD',\n",
    "                order=Store_Sales_Bottom10.sort_values('Sales Amount USD', ascending=True).StoreKey, ax=ax2)\n",
    "    ax2.yaxis.set_major_formatter(formatter)\n",
    "    ax2.set_title('Bottom 10 Stores by Revenue')\n",
    "    ax2.set_xlabel('Store Key')\n",
    "    ax2.set_ylabel('Total Sales (USD)')\n",
    "    for bar in ax2.patches:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, height, f'{height*1e-6:.2f}M', ha='center', va='bottom')\n",
    "\n",
    "    figs.append(fig1)\n",
    "    plt.close(fig1)\n",
    "\n",
    "    # 2. Top and Bottom 10 Stores by Average Order Value (AOV)\n",
    "    Store_AOV = Full_Data.groupby('StoreKey').agg({'Sales Amount USD': 'sum','Order Number': pd.Series.nunique}).reset_index()\n",
    "    Store_AOV['AOV'] = Store_AOV['Sales Amount USD'] / Store_AOV['Order Number']\n",
    "    Store_AOV_Top10 = Store_AOV.sort_values('AOV', ascending=False).head(10)\n",
    "    Store_AOV_Bottom10 = Store_AOV.sort_values('AOV', ascending=True).head(10)  # Use ascending True for bottom\n",
    "\n",
    "    fig2, (ax3, ax4) = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "    sns.barplot(data=Store_AOV_Top10, x='StoreKey', y='AOV',\n",
    "                order=Store_AOV_Top10.sort_values('AOV', ascending=False).StoreKey, ax=ax3)\n",
    "    ax3.set_title('Top 10 Stores by Average Order Value')\n",
    "    ax3.set_xlabel('Store Key')\n",
    "    ax3.set_ylabel('AOV (USD)')\n",
    "    for bar in ax3.patches:\n",
    "        height = bar.get_height()\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, height, f'{height:.2f}', ha='center', va='bottom', rotation=45)\n",
    "\n",
    "    sns.barplot(data=Store_AOV_Bottom10, x='StoreKey', y='AOV',\n",
    "                order=Store_AOV_Bottom10.sort_values('AOV', ascending=True).StoreKey, ax=ax4)\n",
    "    ax4.set_title('Bottom 10 Stores by Average Order Value')\n",
    "    ax4.set_xlabel('Store Key')\n",
    "    ax4.set_ylabel('AOV (USD)')\n",
    "    for bar in ax4.patches:\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2, height, f'{height:.2f}', ha='center', va='bottom', rotation=45)\n",
    "\n",
    "    figs.append(fig2)\n",
    "    plt.close(fig2)\n",
    "\n",
    "    # 3. Monthly Sales: Online vs Physical Stores\n",
    "    Full_Data['Store Type'] = np.where(Full_Data['Square Meters'].isnull(), 'Online', 'Physical')\n",
    "    Store_Type_Sales = Full_Data.groupby([Full_Data['Order Date'].dt.to_period('M'), 'Store Type'],observed=False)['Sales Amount USD'].sum().reset_index()\n",
    "    Store_Type_Sales['Order Date'] = Store_Type_Sales['Order Date'].dt.to_timestamp()\n",
    "    pivot_df = Store_Type_Sales.pivot(index='Order Date', columns='Store Type', values='Sales Amount USD').fillna(0)\n",
    "\n",
    "    fig3, ax5 = plt.subplots(figsize=(12, 8))\n",
    "    sns.lineplot(data=pivot_df, marker='o', ax=ax5)\n",
    "    ax5.yaxis.set_major_formatter(formatter)\n",
    "    ax5.set_title('Monthly Sales: Online vs Physical Stores')\n",
    "    ax5.set_ylabel('Sales Amount (USD)')\n",
    "    ax5.set_xlabel('Month')\n",
    "    ax5.legend(title='Store Type')\n",
    "    figs.append(fig3)\n",
    "    plt.close(fig3)\n",
    "\n",
    "    # 4. Average Sales by Store Age Group\n",
    "    today = pd.to_datetime('2022-01-01') #As we have data till 2021\n",
    "    Full_Data['Store Age (Years)'] = (today - Full_Data['Store Open Date']).dt.days / 365\n",
    "    Full_Data['Store Age Group'] = pd.cut(Full_Data['Store Age (Years)'], bins=[0, 2, 5, 7, 10, 20], labels=['0-2', '2-5', '5-7', '7-10', '10+'])\n",
    "\n",
    "    Age_Impact = Full_Data.groupby('Store Age Group',observed=False)['Sales Amount USD'].mean().reset_index()\n",
    "\n",
    "    fig4, ax6 = plt.subplots(figsize=(12, 6))\n",
    "    bars = sns.barplot(data=Age_Impact, x='Store Age Group', y='Sales Amount USD', ax=ax6)\n",
    "    for bar in bars.patches:\n",
    "        height = bar.get_height()\n",
    "        label = f'${height:.2f}'\n",
    "        if label != '$0.00':\n",
    "            ax6.text(bar.get_x() + bar.get_width()/2, height, label, ha='center', va='bottom')\n",
    "    ax6.set_title('Average Sales by Store Age Group')\n",
    "    ax6.set_ylabel('Average Sales (USD)')\n",
    "    ax6.set_xlabel('Store Age Group (Years)')\n",
    "    figs.append(fig4)\n",
    "    plt.close(fig4)\n",
    "\n",
    "    return figs\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def Analyze_Product_Performance(Full_Data):\n",
    "    figs = []\n",
    "\n",
    "    formatter = ticker.FuncFormatter(lambda x, pos: f'{x*1e-6:.2f}M')\n",
    "    \n",
    "    # 1. Top 10 and Bottom 10 Products by Revenue\n",
    "    Product_Sales = Full_Data.groupby('Product Name',observed=False).agg({'Sales Amount USD':'sum','Profit':'sum'}).reset_index()\n",
    "\n",
    "    Top10_Selling_Products = Product_Sales.sort_values('Sales Amount USD', ascending=False).head(10)\n",
    "    Bottom10_Selling_Products = Product_Sales.sort_values('Sales Amount USD', ascending=True).head(10)\n",
    "\n",
    "    fig1, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,6))\n",
    "    bars1 = ax1.barh(Top10_Selling_Products['Product Name'], Top10_Selling_Products['Sales Amount USD'])\n",
    "    ax1.set_title('Top 10 Products by Revenue')\n",
    "    ax1.set_xlabel('Revenue (USD)')\n",
    "    ax1.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{x*1e-6:.2f}M'))\n",
    "    ax1.tick_params(axis='y', labelsize=6)  # reduced font size\n",
    "    for bar in bars1:\n",
    "        width = bar.get_width()\n",
    "        label = f\"${width * 1e-6:.2f}M\"\n",
    "        ax1.text(width + Top10_Selling_Products['Sales Amount USD'].max() * 0.01, bar.get_y() + bar.get_height() / 2, label, va='center')\n",
    "\n",
    "    bars2 = ax2.barh(Bottom10_Selling_Products['Product Name'], Bottom10_Selling_Products['Sales Amount USD'])\n",
    "    ax2.set_title('Bottom 10 Products by Revenue')\n",
    "    ax2.set_xlabel('Revenue (USD)')\n",
    "    ax2.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{x*1e-3:.2f}K'))\n",
    "    ax2.tick_params(axis='y', labelsize=6)  # reduced font size\n",
    "    for bar in bars2:\n",
    "        width = bar.get_width()\n",
    "        label = f\"${width * 1e-3:.2f}K\"\n",
    "        ax2.text(width + Bottom10_Selling_Products['Sales Amount USD'].max() * 0.01, bar.get_y() + bar.get_height() / 2, label, va='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    figs.append(fig1)\n",
    "    plt.close(fig1)\n",
    "\n",
    "    # 2. Sales Distribution by Product Category (Pie Chart)\n",
    "    Product_Category_Sales = Full_Data.groupby('Category')['Sales Amount USD'].sum()\n",
    "    fig2, ax3 = plt.subplots(figsize=(8,8))\n",
    "    ax3.pie(Product_Category_Sales, labels=Product_Category_Sales.index, autopct='%1.2f%%')\n",
    "    ax3.set_title('Sales Distribution by Product Category')\n",
    "    figs.append(fig2)\n",
    "    plt.close(fig2)\n",
    "\n",
    "    # 3. Sales by Category and Sub-Category (Horizontal Bar)\n",
    "    grouped = Full_Data.groupby(['Category', 'Subcategory'],observed=False)['Sales Amount USD'].sum().reset_index()\n",
    "    category_totals = grouped.groupby('Category')['Sales Amount USD'].sum().sort_values()\n",
    "    grouped['Label'] = grouped['Category'] + ' - ' + grouped['Subcategory']\n",
    "    category_order = category_totals.index.tolist()\n",
    "    grouped['Category'] = pd.Categorical(grouped['Category'], categories=category_order, ordered=True)\n",
    "    grouped = grouped.sort_values(['Category', 'Sales Amount USD'], ascending=[True, True])\n",
    "    palette = sns.color_palette(\"Spectral\", n_colors=len(category_order))\n",
    "    category_colors = dict(zip(category_order, palette))\n",
    "    grouped['Color'] = grouped['Category'].astype(str).map(category_colors)\n",
    "\n",
    "    fig3, ax4 = plt.subplots(figsize=(12,8))\n",
    "    bars = ax4.barh(grouped['Label'], grouped['Sales Amount USD'], color=grouped['Color'])\n",
    "    ax4.set_title('Sales by Category and Sub-Category')\n",
    "    ax4.set_xlabel('Total Sales (USD)')\n",
    "    ax4.set_ylabel('Category - Sub-Category')\n",
    "    ax4.xaxis.set_major_formatter(formatter)\n",
    "    ax4.tick_params(axis='y', labelsize=8)\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        label = f\"${width * 1e-6:.2f}M\"\n",
    "        ax4.text(width + category_totals.max() * 0.01, bar.get_y() + bar.get_height() / 2, label, va='center')\n",
    "    plt.tight_layout()\n",
    "    figs.append(fig3)\n",
    "    plt.close(fig3)\n",
    "\n",
    "    # 4. Top 3 Brands in each Store Country\n",
    "    Brand_Preference = Full_Data.groupby(['Store Country', 'Brand'],observed=False)['Sales Amount USD'].sum().reset_index()\n",
    "    Top3_Brands = Brand_Preference.sort_values(['Store Country', 'Sales Amount USD'], ascending=[True, False])\n",
    "    Top3_Brands = Top3_Brands.groupby('Store Country').head(3)\n",
    "\n",
    "    fig4, ax5 = plt.subplots(figsize=(12,6))\n",
    "    bars = sns.barplot(data=Top3_Brands, x='Store Country', y='Sales Amount USD', hue='Brand', ax=ax5)\n",
    "    ax5.yaxis.set_major_formatter(formatter)\n",
    "    for bar in bars.patches:\n",
    "        height = bar.get_height()\n",
    "        label = f'${height * 1e-6:.2f}M'\n",
    "        if label != '$0.00':\n",
    "            ax5.text(bar.get_x() + bar.get_width() / 2, height, label, ha='center', va='bottom', rotation=90)\n",
    "    ax5.set_title('Top 3 Brands in each Store Country')\n",
    "    ax5.set_xlabel('Store Country')\n",
    "    ax5.set_ylabel('Sales Amount (USD)')\n",
    "    figs.append(fig4)\n",
    "    plt.close(fig4)\n",
    "\n",
    "    return figs\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def Analyze_Delivery_Time(Full_Data):\n",
    "    # 1. Filter out rows with missing Delivery Date\n",
    "    Delivered_Orders = Full_Data[Full_Data['Delivery Date'].notnull()].copy()\n",
    "\n",
    "    # 2. Calculate delivery time (in days)\n",
    "    Delivered_Orders['Delivery_Time_Days'] = (Delivered_Orders['Delivery Date'] - Delivered_Orders['Order Date']).dt.days\n",
    "\n",
    "    # 3. Create plot and return figure\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    sns.histplot(Delivered_Orders['Delivery_Time_Days'], bins=30, kde=True, ax=ax)\n",
    "    ax.set_title('Distribution of Order Delivery Time (Days) for Online Orders')\n",
    "    ax.set_xlabel('Delivery Time (Days)')\n",
    "    ax.set_ylabel('Number of Orders')\n",
    "\n",
    "    return [fig]\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def Analyze_Customers(Full_Data, Customers):\n",
    "    figs = []\n",
    "    \n",
    "    # 1. Gender Distribution (Donut)\n",
    "    gender_counts = Full_Data['Gender'].value_counts()\n",
    "    fig2, ax2 = plt.subplots(figsize=(4,4))\n",
    "    wedges, texts, autotexts = ax2.pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%', startangle=45, colors=['skyblue','lightpink'], wedgeprops={'width':0.4})\n",
    "    centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
    "    ax2.add_artist(centre_circle)\n",
    "    ax2.set_title('Gender Distribution')\n",
    "    figs.append(fig2)\n",
    "    plt.close(fig2)\n",
    "\n",
    "    # 2. Sales by Age Group and Gender\n",
    "    # Calculate Age and Age Group for further analysis\n",
    "    today = pd.Timestamp.today()\n",
    "    Full_Data['Age'] = Full_Data['Birthday'].apply(lambda x: (today - x).days // 365)\n",
    "    bins = [0, 20, 30, 40, 50, 60, 100]\n",
    "    labels = ['<20', '20-29', '30-39', '40-49', '50-59', '60+']\n",
    "    Full_Data['Age_Group'] = pd.cut(Full_Data['Age'], bins=bins, labels=labels)\n",
    "\n",
    "    Age_Gender_Sales = Full_Data.groupby(['Age_Group', 'Gender'],observed=False)['Sales Amount USD'].mean().reset_index()\n",
    "    fig3, ax3 = plt.subplots(figsize=(12,6))\n",
    "    bars = sns.barplot(data=Age_Gender_Sales, x='Age_Group', y='Sales Amount USD', hue='Gender', ax=ax3)\n",
    "    ax3.set_title('Sales by Age Group and Gender')\n",
    "    ax3.set_xlabel('Age Group')\n",
    "    ax3.set_ylabel(\"Avg Sales\")\n",
    "    for bar in bars.patches:\n",
    "        height = bar.get_height()\n",
    "        label = f'${height:.2f}'\n",
    "        if label != '$0.00':\n",
    "            ax3.text(bar.get_x() + bar.get_width() / 2, height, label, ha='center', va='bottom', rotation=5)\n",
    "    figs.append(fig3)\n",
    "    plt.close(fig3)\n",
    "    \n",
    "    # 3. Top 10 Repeat Customers\n",
    "    # Step 1: Count number of purchases and total sales per customer\n",
    "    Repeat_Customers = Full_Data.groupby('CustomerKey').agg({\n",
    "        'Order Date': 'nunique',        # Purchase count (based on unique order dates)\n",
    "        'Sales Amount USD': 'sum'       # Total sales\n",
    "    }).reset_index()\n",
    "    Repeat_Customers.rename(columns={'Order Date':'Purchase_Count','Sales Amount USD':'Total_Sales'}, inplace=True)\n",
    "\n",
    "    # Step 2: Calculate repeat purchase rate\n",
    "    repeat_purchase_rate = Repeat_Customers[Repeat_Customers['Purchase_Count'] > 1]['CustomerKey'].nunique() / Repeat_Customers['CustomerKey'].nunique()\n",
    "    #print(f\"Repeat Purchase Rate: {repeat_purchase_rate:.2%}\")\n",
    "    Total_Customers = Customers['CustomerKey'].nunique()\n",
    "    # Create separate figure with repeat purchase rate text\n",
    "    fig_rate, ax_rate = plt.subplots(figsize=(6, 2))\n",
    "    ax_rate.text(0.5, 0.6, f\"Total Customers:\\n{Total_Customers:,}\", fontsize=16, ha='center', va='center')\n",
    "    ax_rate.text(0.5, 0.4, f\"Repeat Purchase Rate:\\n{repeat_purchase_rate:.2%}\", fontsize=16, ha='center', va='center')\n",
    "    ax_rate.axis('off')\n",
    "    figs.append(fig_rate)\n",
    "    plt.close(fig_rate)\n",
    "\n",
    "    Repeat = Repeat_Customers[Repeat_Customers['Purchase_Count'] > 1]\n",
    "    Repeat_Customer_Detail = pd.merge(Customers, Repeat, on='CustomerKey', how='inner')\n",
    "    Repeat_Customer_Detail = Repeat_Customer_Detail.sort_values(by=['Purchase_Count','Total_Sales'], ascending=[False,False])\n",
    "    Top10_Repeat_Customers = Repeat_Customer_Detail.head(10)\n",
    "    # If purchase count is same then sort by Total sales\n",
    "    Top10_Repeat_Customers = Top10_Repeat_Customers.sort_values(by=['Purchase_Count','Total_Sales'], ascending=[True,True])\n",
    "\n",
    "    # Plot: Top 10 Repeat Customers \n",
    "    fig1, ax1 = plt.subplots(figsize=(12,6))\n",
    "    barh = ax1.barh(Top10_Repeat_Customers['Customer Name'], Top10_Repeat_Customers['Purchase_Count'])\n",
    "    ax1.set_title('Top 10 Repeat Customers')\n",
    "    ax1.set_xlabel('Repeat Frequency')\n",
    "    ax1.set_ylabel('Customer Name')\n",
    "    for bar in barh:\n",
    "        width = bar.get_width()\n",
    "        label = width\n",
    "        ax1.text(width + Top10_Repeat_Customers['Purchase_Count'].max() * 0.01, bar.get_y() + bar.get_height() / 2, label, va='center')\n",
    "    figs.append(fig1)\n",
    "    plt.close(fig1)\n",
    "\n",
    "    return figs\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def create_cover_page():\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.axis('off')  # Hide axes\n",
    "\n",
    "    today = datetime.date.today().strftime(\"%B %d, %Y\")\n",
    "\n",
    "    # Add Title\n",
    "    ax.text(0.5, 0.8, \"Global Electronics Retailer Report\", fontsize=25, ha='center', va='center', weight='bold')\n",
    "\n",
    "    # Add Subtitle\n",
    "    ax.text(0.5, 0.65, \"Comprehensive Sales, Store, Product, and Customer Analysis\", fontsize=16, ha='center', va='center')\n",
    "\n",
    "    # Add Metadata\n",
    "    ax.text(0.5, 0.45, f\"Prepared by: Drishti Patel\\nDate: {today}\", fontsize=12, ha='center', va='center')\n",
    "\n",
    "    return fig\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def save_figures_to_pdf(pdf_path, figures_dict):\n",
    "    \"\"\"\n",
    "    Save matplotlib figures from your analysis functions into a single PDF file.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to save the PDF file.\n",
    "        figures_dict (dict): Dictionary where keys are section titles (str)\n",
    "                             and values are lists of matplotlib figures.\n",
    "    \"\"\"\n",
    "    with PdfPages(pdf_path) as pdf:\n",
    "        # Cover page\n",
    "        cover_fig = create_cover_page()\n",
    "        pdf.savefig(cover_fig)\n",
    "        plt.close(cover_fig)\n",
    "        \n",
    "        for section, figs in figures_dict.items():\n",
    "            figsize=(12, 8)\n",
    "            # title banner at top\n",
    "            title_fig = plt.figure(figsize=(figsize[0],figsize[1])) \n",
    "            plt.text(0.5, 0.5, section, fontsize=25, ha='center', va='center')\n",
    "            plt.axis('off')\n",
    "            pdf.savefig(title_fig)\n",
    "            plt.close(title_fig)\n",
    "\n",
    "            # Save all figures in this section\n",
    "            for fig in figs:\n",
    "                fig.set_size_inches(figsize)  # Force resize\n",
    "                pdf.savefig(fig)\n",
    "                plt.close(fig)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "def main():\n",
    "    # Step 1: Load all raw data\n",
    "    Customers, Products, Stores, Sales, Exchange_Rates = Load_Data()\n",
    "    \n",
    "    # Validate if any dataset is empty\n",
    "    if Customers.empty:\n",
    "        print(\"Error: 'Customers.csv' is empty.\")\n",
    "        return\n",
    "    if Products.empty:\n",
    "        print(\"Error: 'Products.csv' is empty.\")\n",
    "        return\n",
    "    if Stores.empty:\n",
    "        print(\"Error: 'Stores.csv' is empty.\")\n",
    "        return\n",
    "    if Sales.empty:\n",
    "        print(\"Error: 'Sales.csv' is empty.\")\n",
    "        return\n",
    "    if Exchange_Rates.empty:\n",
    "        print(\"Error: 'Exchange_Rates.csv' is empty.\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: Clean each dataset\n",
    "    Customers = Clean_Customer_Data(Customers)\n",
    "    Products = Clean_Product_Data(Products)\n",
    "    Stores = Clean_Store_Data(Stores)\n",
    "    Sales = Clean_Sales_Data(Sales)\n",
    "    Exchange_Rates = Clean_ExchangeRate_Data(Exchange_Rates)\n",
    "    \n",
    "    # Step 3: Combine datasets and calculate sales amount, cost, profit and profit margin\n",
    "    Full_Data = Combine_Data(Customers, Products, Stores, Sales, Exchange_Rates)\n",
    "    \n",
    "    # Step 4: Run analyses and collect figures\n",
    "    figures = {\"Sales Analysis\": Analyze_Sales(Full_Data),\n",
    "               \"Store Performance\": Analyze_Stores(Full_Data),\n",
    "               \"Delivery Time Analysis\": Analyze_Delivery_Time(Full_Data),\n",
    "               \"Product Performance\": Analyze_Product_Performance(Full_Data),\n",
    "               \"Customer Analysis\": Analyze_Customers(Full_Data, Customers),\n",
    "              }\n",
    "    \n",
    "    # Step 5: Save all figures to one PDF\n",
    "    save_figures_to_pdf(\"Output/Global_Electronics_Retailer_Report.pdf\", figures)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ceb6ec-202d-49d2-8364-43067ba497cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
